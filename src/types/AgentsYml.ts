/* eslint-disable */

import { FileStorageConfig } from 'any-cloud-storage';
import { AIConfigRootMetadata, AiConfigPrompt, ModelSettings } from './AIConfig';

/**
 * Definition of `agents.yml` file. Generated by `npm run compile:schema` or `generate:schema`
 */
export interface AgentsYml {
  agents: AgentConfig[];
  /**
   * An array of configuration objects for different models
   */
  config_list?: ModelConfig[];

  // organisations: Array<{
  //   name: string;
  //   /** Default base URL for creating/cloning repositories */
  //   repo_base: string;
  //   /** How & where are stories/issues/alerts managed? */
  //   tasks: Array<{
  //     /** @example # for tasks/stories, ! for alerts */
  //     prefix: string;
  //     /** @example github, jira */
  //     system: string;
  //     base_url: string;
  //   }>;
  // }>;
}

/**
 * Definition of an Agent - name, model/s or how to invoke it, etc.
 * @see https://aiconfig.lastmileai.dev/docs/overview/ai-config-format
 */
export interface AgentConfig {
  /**
   * Short name by which this agent is referred to in a UI etc. Used by VsCode
   */
  name: string;
  /**
   * A human-readable description explaining what this agent does. Used by VsCode & LLM-based routing
   */
  description: string;
  /**
   * Required for compatibility with AIConfig.
   * @example latest
   */
  schema_version?: string;

  metadata?: AIConfigRootMetadata;
  prompts?: AiConfigPrompt[];
  //================== end of AIConfig compatibility ==================

  /**
   * List of model names to filter `llm_config.model_list` by `model`
   */
  models?: string[];
  /**
   * config_list & LLM parameters
   * { temperature: 0.7, max_tokens: 3000, config_list: [{ model: 'gpt-4', api_key: '...' }], ...
   */
  llm_config?: LlmConfig;
  // /**
  //  * System message for the agent. Used by OpenAi
  //  */
  // system_prompt?: string;

  /**
   * Icon for the agent shown in UI. Used by VsCode
   * @see https://code.visualstudio.com/api/references/icons-in-labels#icon-listing
   */
  icon?: string;
  /**
   * When the user clicks this agent in `/help`, this text will be submitted to this slash command. Used by VsCode
   */
  sample_request?: string;

  /** Should the agent be activated in VS Code chat? */
  vscode?: boolean;

  /**
   * The list of slash commands for the agent Used by VsCode, could also be used by OpenAi function calling (with {input:string})
   */
  commands?: SlashCommand[];

  // /**
  //  * AgentProtocol, OpenAI, CLI, VSCode. Used by loadAgent
  //  */
  // type: string;

  /** Configuration for an Agent Protocol client agent */
  remote?: {
    /**
     * The URL of the remote agent
     */
    base_url: string;
  };

  server?: {
    /** @default 8000 */
    port?: number;
    /** @default './workspace' */
    workspace?: string;

    /** By default, files will be saved to disk, but serverless agents can use alternatives using `any-cloud-storage` */
    storage?: FileStorageConfig;
  };

  /**
   * Configuration for a scripted agent Used by CliAgent
   */
  cli?: {
    /**
     * The name of the command, eg: 'python'
     */
    command: string;
    /**
     * Arguments to pass to the command. User prompt will be added after all args.
     * Note that '${workspaceFolder}' will be replaced with the workspace path at run-time.
     * @example ['~/agents/my_agent.py', '--workspace', '${workspaceFolder}']
     */
    args?: string[];
    /**
     * Working directory from which the process is spawned.
     * If not specified, default to the current workding directory.
     * VsCodeChatClient will default it to the workspace folder if a folder is open.
     */
    cwd?: string;
    // repo?: string;
    // daemon?: boolean;
    /** Docker image to run */
    image?: string;
    /** @example ``` */
    wrap_output?: string;
    /**
     * A timeout (in ms) or string or /regex/ to scan for in the output to indicate the end of the command output
     */
    wait_for?: string | number;
  };

  git?: {
    /** Git repo from which the code can be downloaded */
    repo: string;
    /** Defaults to 'origin' */
    remote?: string;
    /** Defaults to 'main' */
    branch?: string;
    /** Installation path */
    baseDir: string;
    /** Should the latest code be pulled on every load? */
    alwaysPull?: boolean;

    options?: {
      /** Base directory for all tasks run through this `simple-git` instance */
      baseDir?: string;
      /** Name of the binary the child processes will spawn - defaults to `git` */
      binary?: string;
      /** Limit for the number of child processes that will be spawned concurrently */
      maxConcurrentProcesses?: number;
      /**
       * Per-command configuration parameters to be passed with the `-c` switch to `git`
       * @example ['user.name=John Doe']
       */
      config?: string[];
      /** Enable trimming of trailing white-space in `git.raw` */
      trimmed?: boolean;
    };
  };

  /**
   * Base path for the workflow. The Agent will use a WorkflowManager to process workflow yaml files.
   */
  workflow_base_path?: string;

  routing?: {
    /** Can be used to improve the ranking of the agent by AgentRegistry.searchAgents() */
    rank?: number;
    /**
     * The roles assigned to the agent, eg: developer, tester. Used by AgentRegistry
     */
    roles?: string[];
    /**
     * The context in which the agent operates, eg: javascript, web... Used by AgentRegistry
     */
    context?: AgentRoutingContext;

    /** Names of other Agents in the team. Creates a RouterAgent */
    team?: string[];

    /** If this agent can not handle a request, will delegate to the fallback */
    fallback?: string;
  };
}

/**
 * The list of slash commands for the agent Used by VsCode, could also be used by OpenAi function calling (with {input:string})
 */
export type SlashCommand = {
  /**
   * The name of the slash command
   */
  name: string;
  /**
   * The description of the slash command
   */
  description: string;

  /** When the user clicks this slash command in `/help`, this text will be submitted to this slash command */
  readonly sampleRequest?: string;

  /**
   * Whether executing the command puts the chat into a persistent mode, where the slash command
   * is prepended to the chat input.
   */
  readonly shouldRepopulate?: boolean;
  /**
   * Placeholder text to render in the chat input when the slash command has been repopulated.
   * Has no effect if `shouldRepopulate` is `false`.
   */
  readonly followupPlaceholder?: string;
};

/**
 * @example ["typescript", "yaml"]
 */
export type RoutingContextValues = string[];
/**
 * The context in which an agent can operate
 * @example { languages: ["typescript", "yaml"], frameworks: ["nodejs"], dependencies: ["openai"], platforms: ["web", "vscode"]}
 */
export type AgentRoutingContext = { [key: string]: RoutingContextValues };

/**
 * If not provided, will be populated by filtering `config_list` by `models`.
 * @see https://github.com/microsoft/autogen/blob/main/samples/apps/autogen-studio/frontend/src/components/types.ts#L28
 */
export interface LlmConfig {
  /** An array of configuration objects for different models */
  config_list: ModelConfig[];
  model_settings?: { [model: string]: ModelSettings };
  // /** Seed for caching and reproducibility (optional) */
  // cache_seed?: number;
  // /** Temperature for the model (optional) */
  // temperature?: number;
  // /**
  //  * Maximum number of tokens in the response (optional)
  //  * @example 3000
  //  */
  // max_tokens?: number;

  // /** @example 1 */
  // top_p?: number; // eg: 1
}
/**
 * An array of these may be stored in a JSON file 'OAI_CONFIG_LIST'
 * @see https://github.com/microsoft/autogen/blob/main/samples/apps/autogen-studio/frontend/src/components/types.ts#L87
 */
export interface ModelConfig {
  /** The model name. eg gpt-4 */
  model: string;
  /** The API key for the model (optional for local LLMs) */
  api_key?: string;
  /** The base URL for the API (optional) */
  base_url?: string;
  /** The type of the API, eg: azure, open_ai (optional) */
  api_type?: string;
  /** The version of the API (optional) */
  api_version?: string;
  // user_id
  // description
}
